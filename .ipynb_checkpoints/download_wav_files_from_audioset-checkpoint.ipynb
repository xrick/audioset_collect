{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd1322c-4090-4986-acc9-6c95b91450e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from audioset_download import Downloader\n",
    "sys.path.append(\"../TransferLearning_for_ACDNet/refine_codes/\");\n",
    "from SharedLibs.datestring import genDataTimeStr,getDateStr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7abb7ceb-649f-4ed2-b759-9a077db9bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwn_sound_name = \"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6364ef9-b04a-415c-a3fb-e0969616eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from setuptools import setup, find_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c412b3-ded5-4aea-b585-9c9ec784653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install audioset-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4b4e067-92b0-44d2-b156-420f7e3ec3b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1691524043.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[42], line 44\u001b[1;36m\u001b[0m\n\u001b[1;33m    class_df = pd.read_csv(\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class Downloader:\n",
    "    \"\"\"\n",
    "    This class implements the download of the AudioSet dataset.\n",
    "    It only downloads the audio files according to the provided list of labels and associated timestamps.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                    root_path: str,\n",
    "                    labels: list = None, # None to download all the dataset\n",
    "                    n_jobs: int = 1,\n",
    "                    download_type: str = 'unbalanced_train',\n",
    "                    copy_and_replicate: bool = True,\n",
    "                    google_seg_file = None\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        This method initializes the class.\n",
    "        :param root_path: root path of the dataset\n",
    "        :param labels: list of labels to download\n",
    "        :param n_jobs: number of parallel jobs\n",
    "        :param download_type: type of download (unbalanced_train, balanced_train, eval)\n",
    "        :param copy_and_replicate: if True, the audio file is copied and replicated for each label. \n",
    "                                    If False, the audio file is stored only once in the folder corresponding to the first label.\n",
    "        \"\"\"\n",
    "        # Set the parameters\n",
    "        self.root_path = root_path\n",
    "        self.labels = labels\n",
    "        self.n_jobs = n_jobs\n",
    "        self.download_type = download_type\n",
    "        self.copy_and_replicate = copy_and_replicate\n",
    "\n",
    "        # Create the path\n",
    "        os.makedirs(self.root_path, exist_ok=True)\n",
    "        self.read_class_mapping()\n",
    "\n",
    "    def read_class_mapping(self):\n",
    "        \"\"\"\n",
    "        This method reads the class mapping.\n",
    "        :return: class mapping\n",
    "        \"\"\"\n",
    "\n",
    "        # class_df = pd.read_csv(\n",
    "        #     f\"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\", \n",
    "        #     sep=',',\n",
    "        # )\n",
    "        class_df = pd.read_csv(\n",
    "            f\"./google_audioset_csv/class_labels_indices.csv\", \n",
    "            sep=',',\n",
    "        )\n",
    "\n",
    "        self.display_to_machine_mapping = dict(zip(class_df['display_name'], class_df['mid']))\n",
    "        self.machine_to_display_mapping = dict(zip(class_df['mid'], class_df['display_name']))\n",
    "        return\n",
    "\n",
    "    def download(\n",
    "        self,\n",
    "        format: str = 'vorbis',\n",
    "        quality: int = 5,    \n",
    "    ):\n",
    "        \"\"\"\n",
    "        This method downloads the dataset using the provided parameters.\n",
    "        :param format: format of the audio file (vorbis, mp3, m4a, wav), default is vorbis\n",
    "        :param quality: quality of the audio file (0: best, 10: worst), default is 5\n",
    "        \"\"\"\n",
    "\n",
    "        self.format = format\n",
    "        self.quality = quality\n",
    "\n",
    "        # Load the metadata\n",
    "        metadata = pd.read_csv(\n",
    "            # f\"http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/{self.download_type}_segments.csv\",\n",
    "            f\"./google_audioset_csv/balanced_train_segments.csv\"\n",
    "            sep=', ', \n",
    "            skiprows=3,\n",
    "            header=None,\n",
    "            names=['YTID', 'start_seconds', 'end_seconds', 'positive_labels'],\n",
    "            engine='python'\n",
    "        )\n",
    "        if self.labels is not None:\n",
    "            print(f\"self.labels:{self.labels}\")\n",
    "            self.real_labels = [self.display_to_machine_mapping[label] for label in self.labels]\n",
    "            metadata = metadata[metadata['positive_labels'].apply(lambda x: any([label in x for label in self.real_labels]))]\n",
    "            # remove \" in the labels\n",
    "        metadata['positive_labels'] = metadata['positive_labels'].apply(lambda x: x.replace('\"', ''))\n",
    "        metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "        print(f'Downloading {len(metadata)} files...')\n",
    "\n",
    "        # Download the dataset\n",
    "        joblib.Parallel(n_jobs=self.n_jobs, verbose=10)(\n",
    "            joblib.delayed(self.download_file)(metadata.loc[i, 'YTID'], metadata.loc[i, 'start_seconds'], metadata.loc[i, 'end_seconds'], metadata.loc[i, 'positive_labels']) for i in range(len(metadata))\n",
    "        )\n",
    "\n",
    "        print('Done.')\n",
    "\n",
    "    def download_file(\n",
    "            self, \n",
    "            ytid: str, \n",
    "            start_seconds: float,\n",
    "            end_seconds: float,\n",
    "            positive_labels: str,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        This method downloads a single file. It only download the audio file at 16kHz.\n",
    "        If a file is associated to multiple labels, it will be stored multiple times.\n",
    "        :param ytid: YouTube ID.\n",
    "        :param start_seconds: start time of the audio clip.\n",
    "        :param end_seconds: end time of the audio clip.\n",
    "        :param positive_labels: labels associated with the audio clip.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create the path for each label that is associated with the file\n",
    "        if self.copy_and_replicate:\n",
    "            for label in positive_labels.split(','):\n",
    "                display_label = self.machine_to_display_mapping[label]\n",
    "                os.makedirs(os.path.join(self.root_path, display_label), exist_ok=True)\n",
    "        else:\n",
    "            display_label = self.machine_to_display_mapping[positive_labels.split(',')[0]]\n",
    "            os.makedirs(os.path.join(self.root_path, display_label), exist_ok=True)\n",
    "\n",
    "        # Download the file using yt-dlp\n",
    "        # store in the folder of the first label\n",
    "        first_display_label = self.machine_to_display_mapping[positive_labels.split(',')[0]]\n",
    "        os.system(f'yt-dlp -x --audio-format {self.format} --audio-quality {self.quality} --output \"{os.path.join(self.root_path, first_display_label, ytid)}_{start_seconds}-{end_seconds}.%(ext)s\" --postprocessor-args \"-ss {start_seconds} -to {end_seconds}\" https://www.youtube.com/watch?v={ytid}')\n",
    "        \n",
    "        if self.copy_and_replicate:\n",
    "            # copy the file in the other folders\n",
    "            for label in positive_labels.split(',')[1:]:\n",
    "                display_label = self.machine_to_display_mapping[label]\n",
    "                os.system(f'cp \"{os.path.join(self.root_path, first_display_label, ytid)}_{start_seconds}-{end_seconds}.wav\" \"{os.path.join(self.root_path, display_label, ytid)}_{start_seconds}-{end_seconds}.wav\"')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28ee4dab-48d3-4867-970f-a750a807d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoke_dl_labels = [\"Smoke detector, smoke alarm\"]\n",
    "dl_labels=[\"moan\"]\n",
    "balanced_alarm_save_path = \"../../Prjects/uec_iot_sound_data_refine_20240226/original_sounds/wail_and_moan/dwntmp/google_audioset/Wail_moan/balanced/\"\n",
    "unbalanced_alarm_save_path = \"../../Prjects/uec_iot_sound_data_refine_20240226/original_sounds/wail_and_moan/dwntmp/google_audioset/Wail_moan/unbalanced/\"\n",
    "eval_alarm_save_path = \"../../Prjects/uec_iot_sound_data_refine_20240226/original_sounds/wail_and_moan/dwntmp/google_audioset/Wail_moan/eval/\"\n",
    "dl_type_balanced = \"balanced_train\"\n",
    "dl_type_unbalanced = \"unbalanced_train\";\n",
    "dl_type_eval = \"eval\"\n",
    "copy_and_repl=True;\n",
    "dl_format = 'wav';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1077e5f8-9ae3-459c-96b2-a71cf68461cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dir(dir):\n",
    "#     if os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f7e91a4-acc8-4df7-a6ae-1497dc325f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.labels:['moan']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'moan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dl_obj_b \u001b[38;5;241m=\u001b[39m Downloader(root_path\u001b[38;5;241m=\u001b[39mbalanced_alarm_save_path, labels\u001b[38;5;241m=\u001b[39mdl_labels, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, download_type\u001b[38;5;241m=\u001b[39mdl_type_balanced, copy_and_replicate\u001b[38;5;241m=\u001b[39mcopy_and_repl)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdl_obj_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 74\u001b[0m, in \u001b[0;36mDownloader.download\u001b[1;34m(self, format, quality)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.labels:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_to_machine_mapping[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels]\n\u001b[0;32m     75\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m metadata[metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28many\u001b[39m([label \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_labels]))]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# remove \" in the labels\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 74\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.labels:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_to_machine_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels]\n\u001b[0;32m     75\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m metadata[metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28many\u001b[39m([label \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_labels]))]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# remove \" in the labels\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'moan'"
     ]
    }
   ],
   "source": [
    "dl_obj_b = Downloader(root_path=balanced_alarm_save_path, labels=dl_labels, n_jobs=6, download_type=dl_type_balanced, copy_and_replicate=copy_and_repl)\n",
    "dl_obj_b.download(format=dl_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4c746-20f6-4490-ba2e-78b79255cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_obj_unb = Downloader(root_path=unbalanced_alarm_save_path, labels=fire_dl_labels, n_jobs=6, download_type=dl_type_unbalanced, copy_and_replicate=copy_and_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb019aef-361d-4979-b4e9-e678631ee844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_obj_eval = Downloader(root_path=eval_alarm_save_path, labels=fire_dl_labels, n_jobs=6, download_type=dl_type_eval, copy_and_replicate=copy_and_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247d4fc5-0df2-4a1e-935a-c8f2a2844e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_obj_unb.download(format = dl_format);\n",
    "# dl_obj_eval.download(format=dl_format);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494c997-6078-4a1c-a462-8ea8198f19a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
